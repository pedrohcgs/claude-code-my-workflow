[
  {
    "objectID": "architecture.html",
    "href": "architecture.html",
    "title": "Architecture Reference",
    "section": "",
    "text": "Claude Code’s power comes from five configuration layers that work together:\n\n\n\n\n\n\n\n\nLayer\nLocation\nLoaded When\n\n\n\n\nCLAUDE.md\nProject root\nEvery session\n\n\nRules\n.claude/rules/\nAlways-on or path-scoped\n\n\nSkills\n.claude/skills/\nOn demand (slash commands)\n\n\nAgents\n.claude/agents/\nOn demand (via skills or orchestrator)\n\n\nHooks\n.claude/settings.json\nOn events (automatic)\n\n\n\nClaude reliably follows about 100–150 custom instructions. Your system prompt uses ~50, leaving ~100 for your project. CLAUDE.md and always-on rules share this budget. Path-scoped rules, skills, and agents load on demand."
  },
  {
    "objectID": "architecture.html#always-on-rules",
    "href": "architecture.html#always-on-rules",
    "title": "Architecture Reference",
    "section": "Always-On Rules",
    "text": "Always-On Rules\nAlways-on rules (no paths: frontmatter) load every session:\n\n\n\n\n\n\n\nRule\nPurpose\n\n\n\n\nplan-first-workflow.md\nPlan before you build\n\n\norchestrator-protocol.md\nDependency-driven contractor mode loop\n\n\nsession-logging.md\nThree logging triggers\n\n\nsession-reporting.md\nConsolidated session report\n\n\nadversarial-pairing.md\nEvery worker has a critic\n\n\nseparation-of-powers.md\nCritics never create, creators never critique\n\n\nthree-strikes.md\nMax 3 rounds, then escalate\n\n\nseverity-gradient.md\nCritic severity by phase\n\n\ndependency-graph.md\nPhases by dependency, not sequence\n\n\nscoring-protocol.md\nWeighted aggregation formula\n\n\nstandalone-access.md\nAny skill works outside the pipeline\n\n\nrevision-protocol.md\nR&R cycle routing\n\n\nresearch-journal.md\nAuto-append journal after agent reports\n\n\nmeta-governance.md\nTemplate vs working project\n\n\ndomain-profile.md\nField-specific calibration"
  },
  {
    "objectID": "architecture.html#path-scoped-rules",
    "href": "architecture.html#path-scoped-rules",
    "title": "Architecture Reference",
    "section": "Path-Scoped Rules",
    "text": "Path-Scoped Rules\nPath-scoped rules load only when relevant:\n\n\n\nRule\nTriggers On\n\n\n\n\nquality-gates.md\n.tex, .R, .do, .py, .jl\n\n\nsingle-source-of-truth.md\nFigures/, .tex\n\n\npdf-processing.md\nmaster_supporting_docs/\n\n\ntable-generator.md\nTables/, .R\n\n\nexploration-folder-protocol.md\nexplorations/\n\n\nexploration-fast-track.md\nexplorations/"
  },
  {
    "objectID": "architecture.html#the-6-worker-critic-pairs",
    "href": "architecture.html#the-6-worker-critic-pairs",
    "title": "Architecture Reference",
    "section": "The 6 Worker-Critic Pairs",
    "text": "The 6 Worker-Critic Pairs\n\n\n\n\n\n\n\n\nWorker (Creates)\nCritic (Reviews)\nPhase\n\n\n\n\nLibrarian — literature collector\nEditor — coverage critic, journal editor\nDiscovery\n\n\nStrategist — identification design\nEconometrician — 4-phase causal audit\nStrategy\n\n\nCoder — implements analysis\nDebugger — 12-category code review\nExecution\n\n\nWriter — drafts paper + humanizer\nProofreader — 6-category manuscript review\nPaper\n\n\nStoryteller — creates Beamer talks\nDiscussant — 5-category talk review\nPresentation\n\n\nReferee (x2) — blind peer review\nEditor — editorial decision\nPeer Review"
  },
  {
    "objectID": "architecture.html#additional-agents",
    "href": "architecture.html#additional-agents",
    "title": "Architecture Reference",
    "section": "Additional Agents",
    "text": "Additional Agents\n\n\n\n\n\n\n\nAgent\nRole\n\n\n\n\nExplorer\nData finder (paired with Surveyor critic)\n\n\nSurveyor\nData quality critic\n\n\nVerifier\nInfrastructure: compilation, execution, AEA compliance\n\n\nOrchestrator\nInfrastructure: dispatch, escalation, rule enforcement"
  },
  {
    "objectID": "architecture.html#all-15-agents",
    "href": "architecture.html#all-15-agents",
    "title": "Architecture Reference",
    "section": "All 15 Agents",
    "text": "All 15 Agents\n\n\n\n\n\n\n\n\nAgent\nFile\nPurpose\n\n\n\n\nLibrarian\nlibrarian.md\nLiterature collection + proximity scoring\n\n\nEditor\neditor.md\nEvolving critic (lit → paper → journal editor)\n\n\nExplorer\nexplorer.md\nData source finder + feasibility scoring\n\n\nSurveyor\nsurveyor.md\nData quality critic\n\n\nStrategist\nstrategist.md\nIdentification strategy + PAP mode\n\n\nEconometrician\neconometrician.md\n4-phase causal inference audit\n\n\nCoder\ncoder.md\nAnalysis implementation (R/Stata/Python/Julia)\n\n\nDebugger\ndebugger.md\n12-category code review\n\n\nWriter\nwriter.md\nPaper drafting + humanizer pass\n\n\nProofreader\nproofreader.md\n6-category manuscript review\n\n\nReferee\nreferee.md\nBlind peer review (x2 instances)\n\n\nStoryteller\nstoryteller.md\nBeamer talk creation (4 formats)\n\n\nDiscussant\ndiscussant.md\nTalk critic (advisory scoring)\n\n\nVerifier\nverifier.md\nStandard (4 checks) + submission (10 checks)\n\n\nOrchestrator\norchestrator.md\nAgent dispatch + escalation routing"
  },
  {
    "objectID": "architecture.html#multi-model-strategy",
    "href": "architecture.html#multi-model-strategy",
    "title": "Architecture Reference",
    "section": "Multi-Model Strategy",
    "text": "Multi-Model Strategy\nNot all agents need the same model. Each agent file has a model: field:\n\n\n\nTask Type\nRecommended Model\nWhy\n\n\n\n\nComplex analysis\nmodel: opus\nNeeds deep reasoning\n\n\nFast, constrained work\nmodel: sonnet\nSpeed matters more\n\n\nDefault\nmodel: inherit\nUses main session model"
  },
  {
    "objectID": "architecture.html#design-principles",
    "href": "architecture.html#design-principles",
    "title": "Architecture Reference",
    "section": "Design Principles",
    "text": "Design Principles\n\nUse command-based hooks for fast, mechanical checks\nUse rules for nuanced judgment\nAvoid prompt-based hooks that trigger LLM calls on every response"
  },
  {
    "objectID": "architecture.html#all-7-hooks",
    "href": "architecture.html#all-7-hooks",
    "title": "Architecture Reference",
    "section": "All 7 Hooks",
    "text": "All 7 Hooks\n\n\n\n\n\n\n\n\nHook\nEvent\nWhat It Does\n\n\n\n\nSession log reminder\nStop\nReminds about session logs\n\n\nDesktop notification\nNotification\nmacOS alert when Claude needs attention\n\n\nFile protection\nPreToolUse\nBlocks edits to bibliography and settings\n\n\nContext state capture\nPreCompact\nSaves plan state + context survival checklist\n\n\nContext restoration\nSessionStart[compact\\|resume]\nRestores context after compaction\n\n\nContext monitor\nPostToolUse[Bash\\|Task]\nProgressive warnings at 40%/55%/65%/80%/90%\n\n\nVerification reminder\nPostToolUse[Write\\|Edit]\nReminds to compile/render (.tex, .R, .do, .py, .jl)"
  },
  {
    "objectID": "architecture.html#the-mental-model",
    "href": "architecture.html#the-mental-model",
    "title": "Architecture Reference",
    "section": "The Mental Model",
    "text": "The Mental Model\nThink of the orchestrator as a general contractor. You are the client. You describe what you want. The plan-first protocol is the blueprint phase. Once you approve the blueprint, the contractor takes over: hires the right specialists (agents), inspects their work (verification), sends them back to fix issues (review-fix loop), and only calls you when the job passes inspection (quality gates)."
  },
  {
    "objectID": "architecture.html#dependency-driven-dispatch",
    "href": "architecture.html#dependency-driven-dispatch",
    "title": "Architecture Reference",
    "section": "Dependency-Driven Dispatch",
    "text": "Dependency-Driven Dispatch\nPhase 1: Discovery (no dependencies)\n  ├── Librarian → Editor (lit review)\n  └── Explorer → Surveyor (data assessment)\n          ↓\nPhase 2: Strategy (depends on Discovery)\n  └── Strategist → Econometrician (strategy memo)\n          ↓\nPhase 3: Execution (depends on Strategy)\n  ├── Coder → Debugger (analysis scripts)\n  └── Writer → Proofreader (paper sections)\n          ↓\nPhase 4: Peer Review (depends on Execution)\n  ├── Referee x2 → Editor (editorial decision)\n  └── paper-excellence (weighted aggregate)\n          ↓\nPhase 5: Submission (depends on Peer Review, score &gt;= 95)\n  └── Verifier (10-check AEA audit)\nPhases activate when dependencies are met, not by forced sequence. Parallel dispatch within phases (e.g., Librarian and Explorer run simultaneously in Phase 1)."
  },
  {
    "objectID": "architecture.html#the-loop",
    "href": "architecture.html#the-loop",
    "title": "Architecture Reference",
    "section": "The Loop",
    "text": "The Loop\nPlan approved → orchestrator activates\n  │\n  Step 1: IMPLEMENT — Execute plan steps\n  │\n  Step 2: VERIFY — Compile, render, check outputs\n  │         If verification fails → fix → re-verify\n  │\n  Step 3: REVIEW — Run worker-critic pairs\n  │\n  Step 4: FIX — Apply fixes (critical → major → minor)\n  │         Max 3 rounds per pair (three-strikes rule)\n  │\n  Step 5: RE-VERIFY — Confirm fixes are clean\n  │\n  Step 6: SCORE — Weighted aggregate per scoring-protocol\n  │\n  └── Score &gt;= threshold?\n        YES → Present summary to user\n        NO  → Loop to Step 3 (max 5 total rounds)\n              After max → present with remaining issues\n\nThree-Strikes Escalation\nIf a worker-critic pair can’t resolve after 3 rounds:\n\n\n\n\n\n\n\nPair\nEscalation Target\n\n\n\n\nCoder + Debugger\n→ Strategist (design may be wrong)\n\n\nWriter + Proofreader\n→ Editor (framing may need rethinking)\n\n\nStrategist + Econometrician\n→ User (fundamental design disagreement)\n\n\nStoryteller + Discussant\n→ Writer (paper content may need revision)\n\n\n\n\n\n“Just Do It” Mode\nWhen you say “just do it”, the orchestrator still runs the full verify-review-fix loop, but skips the final approval pause and auto-commits if the score is &gt;= 80."
  },
  {
    "objectID": "architecture.html#the-protocol",
    "href": "architecture.html#the-protocol",
    "title": "Architecture Reference",
    "section": "The Protocol",
    "text": "The Protocol\nNon-trivial task arrives\n  │\n  Step 1: Enter Plan Mode\n  Step 2: Draft plan (approach, files, verification)\n  Step 3: Save to quality_reports/plans/YYYY-MM-DD_description.md\n  Step 4: Present plan to user\n  Step 5: User approves (or revises)\n  Step 6: Save initial session log\n  Step 7: Orchestrator takes over (dependency-driven dispatch)\n  Step 8: Update session log + plan status to COMPLETED\nPlans are saved to disk so they survive context compression. The rule: avoid /clear — prefer auto-compression."
  },
  {
    "objectID": "architecture.html#session-logging-3-triggers",
    "href": "architecture.html#session-logging-3-triggers",
    "title": "Architecture Reference",
    "section": "Session Logging (3 Triggers)",
    "text": "Session Logging (3 Triggers)\n\nAfter plan approval — create the log with goal, plan summary, rationale\nDuring implementation — append 1–3 lines as design decisions happen\nAt session end — add what was accomplished, open questions, unresolved issues"
  },
  {
    "objectID": "architecture.html#when-to-use",
    "href": "architecture.html#when-to-use",
    "title": "Architecture Reference",
    "section": "When to Use",
    "text": "When to Use\n\n\n\n\n\n\n\n\nScenario\nSequential (slow)\nParallel (fast)\n\n\n\n\nPaper excellence review\nRun each agent sequentially\nRun Econometrician + Debugger + Proofreader + Verifier simultaneously\n\n\nLiterature search\nSearch one database at a time\nSpawn agents for journals, NBER, SSRN\n\n\nData exploration\nCheck one source at a time\nSpawn agents for each data category\n\n\n\nThe orchestrator recognizes independent subtasks and spawns parallel agents automatically."
  },
  {
    "objectID": "architecture.html#practical-limits",
    "href": "architecture.html#practical-limits",
    "title": "Architecture Reference",
    "section": "Practical Limits",
    "text": "Practical Limits\n\n3–4 agents is the sweet spot. More increases overhead without proportional speedup.\nAgents are independent — they cannot see each other’s work. Dependent tasks run sequentially.\nParallel agents multiply token usage."
  },
  {
    "objectID": "architecture.html#creating-talks-from-papers",
    "href": "architecture.html#creating-talks-from-papers",
    "title": "Architecture Reference",
    "section": "Creating Talks from Papers",
    "text": "Creating Talks from Papers\nThe /create-talk skill dispatches the Storyteller (creator) and Discussant (critic) to generate Beamer presentations in 4 formats (job market, seminar, short, lightning). All content derives from Paper/main.tex."
  },
  {
    "objectID": "architecture.html#replication-first-coding",
    "href": "architecture.html#replication-first-coding",
    "title": "Architecture Reference",
    "section": "Replication-First Coding",
    "text": "Replication-First Coding\nWhen working with papers that have replication packages:\nPhase 1: Inventory original code → record \"gold standard\" numbers\nPhase 2: Translate (e.g., Stata → R) → match original spec EXACTLY\nPhase 3: Verify match → tolerance &lt; 0.01 for estimates, &lt; 0.05 for SEs\nPhase 4: Only then extend with new estimators and specifications"
  },
  {
    "objectID": "architecture.html#branch-isolation-with-git-worktrees",
    "href": "architecture.html#branch-isolation-with-git-worktrees",
    "title": "Architecture Reference",
    "section": "Branch Isolation with Git Worktrees",
    "text": "Branch Isolation with Git Worktrees\nGit worktrees create a separate working directory linked to the same repository. Useful for major translations, risky refactors, or multi-day projects.\n\n\n\nSituation\nUse Worktree?\n\n\n\n\nQuick fix to one file\nNo\n\n\nMajor refactor\nYes\n\n\nExperimenting with new approach\nYes\n\n\n\nFor most users, working directly on main with frequent commits is simpler and sufficient."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "The Clo-Author",
    "section": "",
    "text": "An open-source Claude Code workflow that turns your terminal into a full-service applied econometrics research assistant — from literature review to journal submission.\nBuilt on Pedro Sant’Anna’s claude-code-my-workflow, reoriented for applied econometrics research publication."
  },
  {
    "objectID": "index.html#what-you-get",
    "href": "index.html#what-you-get",
    "title": "The Clo-Author",
    "section": "What You Get",
    "text": "What You Get\n\n\n\n\n\n\n\n\nComponent\nCount\nExamples\n\n\n\n\nSpecialized agents\n15\nEconometrician, Writer, Coder, Referee, Strategist\n\n\nSlash commands\n29\n/econometrics-check, /paper-excellence, /new-project\n\n\nAuto-loading rules\n21\nQuality gates, scoring protocol, adversarial pairing\n\n\nHooks\n7\nSession log reminder, context survival, file protection\n\n\n\nYou describe a task in plain English. Claude plans the approach, implements it, runs specialized review agents, fixes issues, verifies quality, and presents results. Like a contractor who manages the entire job."
  },
  {
    "objectID": "index.html#get-started-in-5-minutes",
    "href": "index.html#get-started-in-5-minutes",
    "title": "The Clo-Author",
    "section": "Get Started in 5 Minutes",
    "text": "Get Started in 5 Minutes\n\nStep 1: Fork & Clone\ngh repo fork hsantanna88/clo-author --clone\ncd clo-author\n\n\nStep 2: Start Claude Code\nclaude\nUsing VS Code? Open the Claude Code panel instead. Everything works the same.\n\n\nStep 3: Paste the Starter Prompt\nFill in the bolded placeholders with your project details:\n\nI am starting a new applied econometrics research project on [YOUR TOPIC]. Read CLAUDE.md and help me set up the project structure. Start with a literature review on [YOUR TOPIC].\n\nClaude reads the configuration, fills in your project details, and enters contractor mode — planning, implementing, reviewing, and verifying autonomously.\n\n\nStep 4: Start Working\nOnce setup is done, just describe what you need:\n\n“Review my paper and check the econometrics” — runs /paper-excellence with parallel agents\n/econometrics-check Paper/main.tex — 4-phase causal inference audit\n/data-analysis Data/cleaned/survey.csv — end-to-end analysis with publication-ready output\n/new-project health insurance — full pipeline from idea to paper"
  },
  {
    "objectID": "index.html#what-happens-behind-the-scenes",
    "href": "index.html#what-happens-behind-the-scenes",
    "title": "The Clo-Author",
    "section": "What Happens Behind the Scenes",
    "text": "What Happens Behind the Scenes\nYou talk, Claude orchestrates. The 15 agents work in worker-critic pairs — every creator has a paired critic who can’t edit files, only review. The orchestrator dispatches agents based on a dependency graph, enforces quality gates (80/90/95), and routes escalations when critics and creators can’t agree after 3 rounds.\nFor the full picture, see the User Guide (what you can do) and Architecture Reference (how the system works)."
  },
  {
    "objectID": "index.html#day-1-checklist",
    "href": "index.html#day-1-checklist",
    "title": "The Clo-Author",
    "section": "Day 1 Checklist",
    "text": "Day 1 Checklist\n\nFork the repo and clone it locally\nRun claude in the project directory\nPaste the starter prompt (fill in your project details)\nWait for Claude to customize CLAUDE.md for your project\nApprove the configuration plan\nAsk Claude to do something: “Review my paper” or “/lit-review [topic]”\nApprove the task plan, watch it work, review the output\n\nThat’s it. Everything else — agents, hooks, rules — runs automatically in the background.\n\n\n\n\n\n\nNoteOptional: Manual Setup\n\n\n\n\n\nIf you prefer to configure things yourself instead of letting Claude handle it:\nCustomize CLAUDE.md — Open CLAUDE.md and replace all [BRACKETED PLACEHOLDERS]:\n\nProject name and institution\nFolder structure (adjust to your layout)\nCurrent project state (your papers and analyses)\n\nFill in the domain profile — Run /interview-me or manually edit .claude/rules/domain-profile.md:\n\nYour field and adjacent subfields\nTarget journals ranked by tier\nCommon data sources and identification strategies\nField conventions and seminal references\n\nConfigure permissions — Review .claude/settings.json. The template includes permissions for git, LaTeX, R, and utility scripts.\nTest it:\n/compile-latex main\n/proofread Paper/main.tex"
  },
  {
    "objectID": "index.html#prerequisites",
    "href": "index.html#prerequisites",
    "title": "The Clo-Author",
    "section": "Prerequisites",
    "text": "Prerequisites\n\n\n\nTool\nRequired For\nInstall\n\n\n\n\nClaude Code\nEverything\nnpm install -g @anthropic-ai/claude-code\n\n\nXeLaTeX\nPaper compilation\nTeX Live or MacTeX\n\n\nR\nAnalysis & figures\nr-project.org\n\n\ngh CLI\nGitHub integration\nbrew install gh (macOS)\n\n\n\nOptional: Stata, Python, Julia (multi-language analysis), Quarto (web slides)."
  },
  {
    "objectID": "index.html#origin",
    "href": "index.html#origin",
    "title": "The Clo-Author",
    "section": "Origin",
    "text": "Origin\nThis project is a fork of Pedro Sant’Anna’s claude-code-my-workflow, which was built for Econ 730 at Emory University (6 lectures, 800+ slides). The Clo-Author reorients that infrastructure from lecture production to applied econometrics research publication.\nMaintained by Hugo Sant’Anna. MIT License — fork it, customize it, make it yours."
  },
  {
    "objectID": "user-guide.html",
    "href": "user-guide.html",
    "title": "User Guide",
    "section": "",
    "text": "You describe what you want in plain English. Claude handles the rest.\n\n\n\nYou Do\nHappens Automatically\n\n\n\n\nDescribe what you want\nClaude selects and runs the right skills\n\n\nApprove plans\nOrchestrator coordinates agents via dependency graph\n\n\nReview final output\nWorker-critic pairs ensure quality\n\n\nSay “commit” when ready\nQuality gates enforce score thresholds\n\n\n\nFor complex or ambiguous tasks, Claude may ask 3–5 clarifying questions to create a requirements specification before planning. Each requirement is tagged MUST/SHOULD/MAY, and each aspect is marked CLEAR/ASSUMED/BLOCKED."
  },
  {
    "objectID": "user-guide.html#writing-your-paper",
    "href": "user-guide.html#writing-your-paper",
    "title": "User Guide",
    "section": "Writing Your Paper",
    "text": "Writing Your Paper\n\n/draft-paper [section]\nDispatches the Writer agent. Drafts paper sections with proper economics structure:\n\nIntroduction: contribution paragraph within first 2 pages, effect sizes stated, clear identification preview\nEmpirical Strategy: per-design template (DiD, IV, RDD, etc.) with assumption discussion\nResults: proper table/figure references, statistical vs economic significance\nNotation protocol: \\(Y_{it}\\), \\(D_{it}\\), \\(ATT(g,t)\\) — consistent throughout\n\nAnti-hedging rules enforced. Humanizer pass automatically strips 24 AI writing patterns.\n\n\n/review-paper [file]\nDispatches 2 Referee agents (blind, parallel) and the Editor agent. Simulates peer review with independent reports and editorial decision (Accept/Minor/Major/Reject).\n\n\n/respond-to-referee [report]\nClassifies each referee comment per revision-protocol.md:\n\n\n\n\n\n\n\n\nClass\nRouting\nAction\n\n\n\n\nNEW ANALYSIS\n→ Coder\nFlag for user, create analysis task\n\n\nCLARIFICATION\n→ Writer\nDraft revised text\n\n\nDISAGREE\n→ User\nDraft diplomatic pushback (flagged for review)\n\n\nMINOR\n→ Writer\nDraft fix directly\n\n\n\nProduces point-by-point response letter with diplomatic disagreement protocol."
  },
  {
    "objectID": "user-guide.html#running-analysis",
    "href": "user-guide.html#running-analysis",
    "title": "User Guide",
    "section": "Running Analysis",
    "text": "Running Analysis\n\n/data-analysis [dataset]\nDispatches the Coder (implementer) and Debugger (code critic). End-to-end analysis: data cleaning, main specification, robustness checks, publication-ready output. Supports R, Stata, Python, and Julia.\n\n\n/econometrics-check [file]\nThe centerpiece agent. Dispatches the Econometrician for 4 sequential phases with early stopping:\n\n\n\n\n\n\n\nPhase\nWhat It Does\n\n\n\n\n1. What’s the Claim?\nIdentify the design (DiD/IV/RDD/SC/Event Study), estimand, treatment, control. Early stops if no causal claims.\n\n\n2. Core Design Validity\nDesign-specific assumption checks (3–5 critical items) plus mandatory sanity check — sign, magnitude, dynamics. Early stops on critical issues.\n\n\n3. Inference\nSE clustering, few-clusters correction, multiple testing, code-theory alignment with package-specific checks.\n\n\n4. Polish\nRobustness (Oster bounds, placebos, alternative specs), assumption stress test, citation fidelity. Only runs if Phases 2–3 pass.\n\n\n\nPackage-flexible: Recommends best practices but accepts and validates alternative packages.\n\n\n/find-data [question]\nDispatches the Explorer (data finder) and Surveyor (data critic). Searches public, administrative, survey, and novel data sources. Scores feasibility (A/B/C/D) and measurement quality.\n\n\n/identify [question]\nDispatches the Strategist (proposer) and Econometrician (critic). Produces strategy memo, pseudo-code, robustness plan, and falsification tests."
  },
  {
    "objectID": "user-guide.html#preparing-for-submission",
    "href": "user-guide.html#preparing-for-submission",
    "title": "User Guide",
    "section": "Preparing for Submission",
    "text": "Preparing for Submission\n\n/pre-analysis-plan [spec]\nDispatches the Strategist in PAP mode. Drafts in AEA/OSF/EGAP format with outcomes, subgroups, multiple testing corrections, and power calculations.\n\n\n/audit-replication [dir]\nDispatches the Verifier in submission mode (all 10 checks):\n\nLaTeX compilation\nScript execution\nFile integrity\nOutput freshness\nPackage inventory\nDependency verification\nData provenance\nEnd-to-end execution\nOutput cross-reference\nREADME completeness (AEA format)\n\n\n\n/data-deposit\nDispatches Coder (assembly) and Verifier (validation). Generates AEA-format README, master script, numbered script order, and deposit checklist.\n\n\n/target-journal [paper]\nDispatches the Editor in journal-selection mode. Produces ranked journal list using domain-profile tiers, formatting requirements, and submission strategy.\n\n\n/submit [journal]\nFinal submission gate. Requires aggregate score &gt;= 95 with all components &gt;= 80. Generates cover letter draft and submission checklist."
  },
  {
    "objectID": "user-guide.html#giving-a-talk",
    "href": "user-guide.html#giving-a-talk",
    "title": "User Guide",
    "section": "Giving a Talk",
    "text": "Giving a Talk\n\n/create-talk [format]\nDispatches the Storyteller (creator) and Discussant (critic). Generates Beamer .tex talks derived from your paper in 4 formats:\n\n\n\n\n\n\n\n\n\nFormat\nSlides\nDuration\nContent\n\n\n\n\nJob Market\n40–50\n45–60 min\nFull story, all results, mechanism, robustness\n\n\nSeminar\n25–35\n30–45 min\nMotivation, main result, 2 robustness checks\n\n\nShort\n10–15\n15 min\nQuestion, method, key result, implication\n\n\nLightning\n3–5\n5 min\nHook, result, so-what\n\n\n\nTalk scores are advisory (non-blocking)."
  },
  {
    "objectID": "user-guide.html#quick-corrections-learn-tags",
    "href": "user-guide.html#quick-corrections-learn-tags",
    "title": "User Guide",
    "section": "Quick Corrections: [LEARN] Tags",
    "text": "Quick Corrections: [LEARN] Tags\nEvery correction gets tagged for future reference in MEMORY.md:\n- [LEARN:notation] T_t = 1{t=2} is deterministic -&gt; use T_i in {1,2}\n- [LEARN:citation] Post-LASSO is Belloni (2013), NOT Belloni (2014)\n- [LEARN:r-code] Package X: ALWAYS include intercept in design matrix"
  },
  {
    "objectID": "user-guide.html#skill-extraction-learn",
    "href": "user-guide.html#skill-extraction-learn",
    "title": "User Guide",
    "section": "Skill Extraction: /learn",
    "text": "Skill Extraction: /learn\nFor discoveries that deserve more than a one-line tag, use /learn to create a full skill.\n\n\n\n\n\n\n\nSituation\nUse\n\n\n\n\nOne-liner fix\n[LEARN:category] tag in MEMORY.md\n\n\nMulti-step workflow\n/learn to create full skill\n\n\nError + root cause + solution\n/learn if reusable, [LEARN] if not"
  },
  {
    "objectID": "user-guide.html#domain-profile",
    "href": "user-guide.html#domain-profile",
    "title": "User Guide",
    "section": "Domain Profile",
    "text": "Domain Profile\nThe domain profile (.claude/rules/domain-profile.md) calibrates all agents to your field. Fill it in manually or use /interview-me to populate it interactively:\n\nField & adjacent subfields — inferred from your topic\nTarget journals — ranked by tier\nCommon data sources — datasets typical for your area\nCommon identification strategies — designs used in your literature\nField conventions — estimation quirks, clustering norms\nSeminal references — papers every referee expects you to cite\nReferee concerns — the “gotcha” questions referees always ask"
  },
  {
    "objectID": "user-guide.html#sec-create-skills",
    "href": "user-guide.html#sec-create-skills",
    "title": "User Guide",
    "section": "Creating Custom Skills",
    "text": "Creating Custom Skills\nCreate a skill when you repeatedly explain the same 3+ step workflow to Claude. Each skill lives in .claude/skills/[name]/SKILL.md:\n---\nname: your-skill-name\ndescription: [What it does] + [When to use] + [Key capabilities]\nargument-hint: \"[brief hint for user]\"\nallowed-tools: [\"Read\", \"Write\", \"Edit\", \"Bash\", \"Task\"]\n---\nQuick start: Copy templates/skill-template.md to .claude/skills/your-skill-name/SKILL.md and customize."
  },
  {
    "objectID": "user-guide.html#research-pipeline",
    "href": "user-guide.html#research-pipeline",
    "title": "User Guide",
    "section": "Research Pipeline",
    "text": "Research Pipeline\n\n\n\n\n\n\n\n\nSkill\nAgents\nWhat It Does\n\n\n\n\n/new-project [topic]\nAll (orchestrated)\nFull pipeline: idea → paper\n\n\n/interview-me [topic]\n—\nInteractive Q&A → research spec + domain profile\n\n\n/lit-review [topic]\nLibrarian + Editor\nLiterature search + synthesis\n\n\n/find-data [question]\nExplorer + Surveyor\nData discovery + quality assessment\n\n\n/identify [question]\nStrategist + Econometrician\nDesign identification strategy\n\n\n/research-ideation [topic]\n—\nResearch questions + strategies"
  },
  {
    "objectID": "user-guide.html#analysis-code",
    "href": "user-guide.html#analysis-code",
    "title": "User Guide",
    "section": "Analysis & Code",
    "text": "Analysis & Code\n\n\n\n\n\n\n\n\nSkill\nAgents\nWhat It Does\n\n\n\n\n/data-analysis [dataset]\nCoder + Debugger\nEnd-to-end analysis\n\n\n/econometrics-check [file]\nEconometrician\n4-phase causal inference audit\n\n\n/review-r [file]\nDebugger\nCode quality review (standalone)"
  },
  {
    "objectID": "user-guide.html#writing-polish",
    "href": "user-guide.html#writing-polish",
    "title": "User Guide",
    "section": "Writing & Polish",
    "text": "Writing & Polish\n\n\n\nSkill\nAgents\nWhat It Does\n\n\n\n\n/draft-paper [section]\nWriter\nPaper sections + humanizer pass\n\n\n/proofread [file]\nProofreader\n6-category manuscript review\n\n\n/humanizer [file]\n—\nStrip 24 AI writing patterns\n\n\n/compile-latex [file]\n—\n3-pass XeLaTeX + BibTeX"
  },
  {
    "objectID": "user-guide.html#quality-review",
    "href": "user-guide.html#quality-review",
    "title": "User Guide",
    "section": "Quality & Review",
    "text": "Quality & Review\n\n\n\n\n\n\n\n\nSkill\nAgents\nWhat It Does\n\n\n\n\n/paper-excellence [file]\n4 parallel\nMulti-agent review + weighted score\n\n\n/review-paper [file]\n2 Referees + Editor\nSimulated peer review\n\n\n/validate-bib\n—\nCross-reference citations"
  },
  {
    "objectID": "user-guide.html#submission-deposit",
    "href": "user-guide.html#submission-deposit",
    "title": "User Guide",
    "section": "Submission & Deposit",
    "text": "Submission & Deposit\n\n\n\n\n\n\n\n\nSkill\nAgents\nWhat It Does\n\n\n\n\n/target-journal [paper]\nEditor\nJournal targeting + strategy\n\n\n/respond-to-referee [report]\nWriter + routing\nPoint-by-point response\n\n\n/data-deposit\nCoder + Verifier\nAEA replication package\n\n\n/audit-replication [dir]\nVerifier\n10-check submission audit\n\n\n/pre-analysis-plan [spec]\nStrategist\nDraft PAP (AEA/OSF/EGAP)\n\n\n/submit [journal]\nVerifier + scoring\nFinal gate (score &gt;= 95)"
  },
  {
    "objectID": "user-guide.html#presentations",
    "href": "user-guide.html#presentations",
    "title": "User Guide",
    "section": "Presentations",
    "text": "Presentations\n\n\n\n\n\n\n\n\nSkill\nAgents\nWhat It Does\n\n\n\n\n/create-talk [format]\nStoryteller + Discussant\nBeamer talk (4 formats)\n\n\n/visual-audit [file]\n—\nSlide layout audit"
  },
  {
    "objectID": "user-guide.html#infrastructure",
    "href": "user-guide.html#infrastructure",
    "title": "User Guide",
    "section": "Infrastructure",
    "text": "Infrastructure\n\n\n\nSkill\nWhat It Does\n\n\n\n\n/commit [msg]\nStage, commit, PR, merge\n\n\n/learn\nExtract session discoveries into persistent skills\n\n\n/context-status\nShow session health and context usage\n\n\n/deploy\nBuild and deploy to GitHub Pages\n\n\n/journal\nResearch journal timeline"
  }
]